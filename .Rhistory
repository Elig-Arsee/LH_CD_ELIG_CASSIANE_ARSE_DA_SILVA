#INSTALANDO PACOTES
install.packages("dlookr") #caso pacote não esteja instalado
#INSTALANDO PACOTES
install.packages("dlookr") #caso pacote não esteja instalado
#INSTALANDO PACOTES
install.packages("dlookr") #caso pacote não esteja instalado
library(dlookr)
## Carregando datasets
cars_train <- read.csv(file = "cars_train.csv",sep = "\t", fileEncoding = "UTF-16le")
cars_test <- read.csv(file = "cars_test.csv", sep = "\t", fileEncoding = "UTF-16le")
## Visualizando banco
View(cars_train)
glimpse(cars_train)
## verificando observações duplicadas
duplicated(cars_train$id)
sum(duplicated(cars_train$id))# sem observações duplicadas
duplicated(cars_test$id)
sum(duplicated(cars_test$id)) # sem observações duplicadas
## Excluindo a coluna id
d_treino <- cars_train [-1]
d_teste <- cars_test [-1]
library(dlookr)
# transformando banco em dataframe
d_treino <- as.data.frame(d_treino)
# gerando relatório automático do banco
#se você estiver usando o RStudio, vá para FERRAMENTAS >
#OPÇÕES GLOBAIS > SWEAVE e marque "Usar TinyTex ao compilar arquivos .tex".
eda_paged_report(d_treino,
output_format = "pdf",
output_file = "df_treino1.pdf",
title = "Desafio Lighthouse: EDA",
author = "Elig Cassiane Arse da Silva",
create_date = "",
theme = "blue")
#INSTALANDO PACOTES
install.packages("dlookr") #caso pacote não esteja instalado
install.packages("dlookr")
library(dlookr)
# gerando relatório automático do banco
#se você estiver usando o RStudio, vá para FERRAMENTAS >
#OPÇÕES GLOBAIS > SWEAVE e marque "Usar TinyTex ao compilar arquivos .tex".
eda_paged_report(d_treino,
output_format = "pdf",
output_file = "df_treino1.pdf",
title = "Desafio Lighthouse: EDA",
author = "Elig Cassiane Arse da Silva",
create_date = "",
theme = "blue")
library(randomForest)
library(dplyr)
library(tidyverse)
library(caret)
library(fastDummies)
library(doParallel)
load("C:/Users/mat24/Desktop/Elig/dados rodados.RData")
set.seed(2023)
train_indices <- sample(1:nrow(df_numeric), nrow(df_numeric) * 0.7)
train_set <- df_numeric[train_indices, ]
test_set <- df_numeric[-train_indices, ]
no_cores <- detectCores() - 1
registerDoParallel(cores = no_cores)
# Aqui usamos o ntree de 500 arvores, que é o padrão
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 7,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 5,
method = "repeatedcv",
verboseIter = TRUE,
)
)
teste = df_numeric[1:550]
teste = df_numeric[1:550]
set.seed(2023)
train_indices <- sample(1:nrow(teste), nrow(teste) * 0.7)
train_set <- teste[train_indices, ]
test_set <- teste[-train_indices, ]
no_cores <- detectCores() - 1
registerDoParallel(cores = no_cores)
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 5,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 5,
method = "repeatedcv",
verboseIter = TRUE,
)
)
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 5,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 5,
method = "repeatedcv",
verboseIter = TRUE
)
)
save.image("C:/Users/mat24/Desktop/Elig/teste.RData")
library(randomForest)
library(dplyr)
library(tidyverse)
library(caret)
library(fastDummies)
library(doParallel)
teste = df_numeric[1:550]
teste = df_numeric[1:550,]
set.seed(2023)
train_indices <- sample(1:nrow(teste), nrow(teste) * 0.7)
train_set <- teste[train_indices, ]
test_set <- teste[-train_indices, ]
no_cores <- detectCores() - 1
registerDoParallel(cores = no_cores)
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 5,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 5,
method = "repeatedcv",
verboseIter = TRUE
)
)
library(randomForest)
library(dplyr)
library(tidyverse)
library(caret)
library(fastDummies)
library(doParallel)
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 5,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 5,
method = "repeatedcv",
verboseIter = TRUE
)
)
stopCluster(cl)
predict(cars_test, modelr)
predict(cars_test, model_random_forests)
predict(model_random_forests, cars_test)
test_dummies <- fastDummies::dummy_cols(cars_test)
predict(model_random_forests, test_dummies)
missing_cols <- setdiff(names(df_numeric), names(test_dummies))
test2 = test_dummies
test_dummies[missing_cols] <- 0
missing_cols <- setdiff(names(df_numeric), names(test_dummies))
test_dummies[missing_cols] <- 0
predict(model_random_forests, test_dummies)
missing_cols <- setdiff(names(df_dummies), names(test_dummies))
test_dummies[missing_cols] <- 0
View(test_dummies)
setdiff(names(test_dummies), names(df_dummies))
# Assuming dados_treino is your dataframe
# Fill NA values with median for numeric variables
numeric_vars <- sapply(dados_treino, is.numeric)
dados_treino[numeric_vars] <- lapply(dados_treino[numeric_vars], function(x) ifelse(is.na(x), median(x, na.rm = TRUE), x))
# Fill NA values with mode for categorical variables
categorical_vars <- sapply(dados_treino, is.character)
dados_treino[categorical_vars] <- lapply(dados_treino[categorical_vars], function(x) ifelse(is.na(x), names(which.max(table(x))), x))
#setdiff(colnames(dados_treino1), colnames(dados_treino))
dados_treino %>% select(-cidade_vendedor)
#setdiff(colnames(dados_treino1), colnames(dados_treino))
dados_treino2 = dados_treino %>% select(-cidade_vendedor)
setdiff(names(test_dummies), names(df_dummies))
predict(model_random_forests, test_dummies)
teste_numeric <- test_dummies %>% select(where(is.numeric))
predict(model_random_forests, teste_numeric)
View(teste_numeric)
v= na.omit(teste_numeric)
teste_numeric <- replace(teste_numeric, is.na(teste_numeric), 0)
predict(model_random_forests, teste_numeric)
testeeeee = predict(model_random_forests, teste_numeric)
set.seed(2023)
train_indices <- sample(1:nrow(df_numeric), nrow(df_numeric) * 0.7)
train_set <- df_numeric[train_indices, ]
test_set <- df_numeric[-train_indices, ]
no_cores <- detectCores() - 1
cl <- makePSOCKcluster(no_cores); registerDoParallel(cl);
stopCluster(cl)
no_cores <- detectCores() - 1
cl <- makePSOCKcluster(no_cores); registerDoParallel(cl);
no_cores <- detectCores() - 1
cl <- makePSOCKcluster(no_cores); registerDoParallel(cl);
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 5,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 3,
method = "repeatedcv",
verboseIter = TRUE
)
)
stopCluster(cl)
model_random_forests <- caret::train(
#preco ~ .,
x = train_set %>% select(-preco),
y = train_set$preco,
method = "rf",
tuneLength = 5,
metric = "RMSE",
trControl= trainControl(
allowParallel = TRUE,
number = 5,
repeats = 3,
method = "repeatedcv",
verboseIter = TRUE
)
)
save.image("C:/Users/mat24/Desktop/Elig/t.RData")
setwd("C:/Users/mat24/Desktop/Elig")
setwd("C:/Users/mat24/Desktop/Elig")
load("C:/Users/mat24/Desktop/Elig/Random forest rodado.RData")
stopCluster(cl)
test_dummies <- fastDummies::dummy_cols(cars_test)
setdiff(names(df_dummies), names(test_dummies))
test_dummies[missing_cols] <- 0
missing_cols = setdiff(names(df_dummies), names(test_dummies))
test_dummies[missing_cols] <- 0
teste_numeric <- test_dummies %>% select(where(is.numeric))
library(randomForest)
library(dplyr)
library(tidyverse)
library(caret)
library(fastDummies)
library(parallel)
library(doParallel)
teste_numeric <- test_dummies %>% select(where(is.numeric))
teste_numeric <- replace(teste_numeric, is.na(teste_numeric), 0)
# Aqui fazemos a previsao com o modelo
prediction = predict(model_random_forests, teste_numeric)
id = cars_test$id
precos_preditos = as.data.frame(cbind(id, prediction))
library(xlsx)
write.xlsx(precos_preditos, "precos_preditos.xlsx")
precos_preditos = as.data.frame(cbind(id, prediction))
colnames(precos_preditos) = c("id", "price")
write.xlsx(precos_preditos, "precos_preditos.xlsx")
ggplot(model_random_forests) +
geom_line(size = 1.3) +
geom_point(size = 5) +
geom_vline(xintercept = model_random_forests$bestTune$mtry, linetype = "dashed", alpha = 0.5, size = 1) +
theme_bw(base_size = 22) +
theme(aspect.ratio = 1)
ggsave(
filename = "cross_validation_result.pdf",
device = "pdf",
width = 9,
height = 7)
